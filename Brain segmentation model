{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":4310761,"sourceType":"datasetVersion","datasetId":2539169}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"to split image into small patches.","metadata":{}},{"cell_type":"code","source":"pip install patchify","metadata":{"execution":{"iopub.status.busy":"2024-04-25T20:42:53.317748Z","iopub.execute_input":"2024-04-25T20:42:53.318484Z","iopub.status.idle":"2024-04-25T20:43:06.290672Z","shell.execute_reply.started":"2024-04-25T20:42:53.318447Z","shell.execute_reply":"2024-04-25T20:43:06.289588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## UNETR model Configration","metadata":{}},{"cell_type":"code","source":"\"\"\" UNETR Configration \"\"\"\n\nfrom keras.optimizers import Adam\n\ncf = {}\ncf[\"image_size\"] = 256\ncf[\"num_layers\"] = 12\ncf[\"hidden_dim\"] = 128\ncf[\"mlp_dim\"] = 32\ncf[\"num_heads\"] = 6\ncf[\"dropout_rate\"] = 0.1\ncf[\"batch_size\"] = 16\ncf[\"lr\"] = 1e-4\ncf[\"optimizer\"] = Adam(cf[\"lr\"])\ncf[\"patch_size\"] = 16\ncf[\"num_patches\"] = (cf[\"image_size\"] ** 2) // (cf[\"patch_size\"] ** 2)\ncf[\"num_channels\"] = 3\ncf[\"flat_patches_shape\"] = (\n    cf[\"num_patches\"],\n    cf[\"patch_size\"] * cf[\"patch_size\"] * cf[\"num_channels\"]\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-25T20:43:13.145425Z","iopub.execute_input":"2024-04-25T20:43:13.146114Z","iopub.status.idle":"2024-04-25T20:43:26.151944Z","shell.execute_reply.started":"2024-04-25T20:43:13.146079Z","shell.execute_reply":"2024-04-25T20:43:26.150879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from glob import glob\nimport os\nfrom sklearn.model_selection import train_test_split\nimport cv2\nimport numpy as np\nimport tensorflow as tf\nfrom patchify import patchify\nfrom keras.preprocessing.image import ImageDataGenerator\n\n\ndef create_dir(path):\n    if not os.path.exists(path):\n        os.makedirs(path)\n\n\ndef load_dataset(path, split=0.2):\n    # Get paths of images and masks\n    images_paths = sorted(glob(os.path.join(path, \"images\", \"*.png\")))\n    masks_paths = sorted(glob(os.path.join(path, \"masks\", \"*.png\")))\n\n    split_size = int(len(images_paths) * split)\n\n    train_x, valid_x = train_test_split(\n        images_paths, test_size=split_size, random_state=42)\n    train_y, valid_y = train_test_split(\n        masks_paths, test_size=split_size, random_state=42)\n\n    train_x, test_x = train_test_split(\n        train_x, test_size=split_size, random_state=42)\n    train_y, test_y = train_test_split(\n        train_y, test_size=split_size, random_state=42)\n\n    return (train_x, train_y), (valid_x, valid_y), (test_x, test_y)\n    return (train_x, train_y), (valid_x, valid_y), (test_x, test_y)\n\n\ndef augment_data(images_paths, masks_paths, num_aug_per_image=2, aug_save_path=\"/kaggle/working/Augmented_Dataset\"):\n    \"\"\"\n    Perform data augmentation on images and masks.\n\n    Args:\n        images_paths (list): List of file paths to original images.\n        masks_paths (list): List of file paths to corresponding masks.\n        num_aug_per_image (int, optional): Number of augmented versions to create per image. Defaults to 3.\n        aug_save_path (str, optional): Directory to save augmented images and masks. Defaults to \"Augmented_Dataset\".\n\n    Returns:\n        tuple: A tuple containing lists of augmented image paths and mask paths.\n    \"\"\"\n    # Create directories to save augmented images and masks\n    images_aug_dir = os.path.join(aug_save_path, \"images\")\n    masks_aug_dir = os.path.join(aug_save_path, \"masks\")\n\n    create_dir(images_aug_dir)\n    create_dir(masks_aug_dir)\n\n    for (img_path, mask_path) in zip(images_paths, masks_paths):\n        # Read the image and mask\n        image = cv2.imread(img_path, cv2.IMREAD_COLOR)\n        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n\n        # Initialize an ImageDataGenerator for augmentation\n        aug = ImageDataGenerator(\n            rotation_range=10,\n            zoom_range=0.2,\n            brightness_range=[0.7, 1.3],\n            horizontal_flip=True,\n            fill_mode=\"nearest\"\n        )\n\n        # Extract the base filename (without extension) for saving augmented images\n        id = os.path.splitext(os.path.basename(img_path))[0]\n\n        # Augment the image\n        num_aug = 0\n        for _ in aug.flow(np.expand_dims(image, axis=0), batch_size=1, save_to_dir=images_aug_dir, save_prefix=f\"{id}_aug\", save_format=\"png\", seed=42):\n            num_aug += 1\n            if num_aug >= num_aug_per_image:\n                break\n\n        # Augment the mask\n        num_aug = 0\n        for _ in aug.flow(np.expand_dims(mask, axis=(0, -1)), batch_size=1, save_to_dir=masks_aug_dir, save_prefix=f\"{id}_aug\", save_format=\"png\", seed=42):\n            num_aug += 1\n            if num_aug >= num_aug_per_image:\n                break\n\n    # Get paths of augmented images and masks\n    aug_images_paths = sorted(\n        glob(os.path.join(aug_save_path, \"images\", \"*.png\")))\n    aug_masks_paths = sorted(\n        glob(os.path.join(aug_save_path, \"masks\", \"*.png\")))\n\n    # Combine original and augmented paths\n    images_paths.extend(aug_images_paths)\n    masks_paths.extend(aug_masks_paths)\n\n    return images_paths, masks_paths\n\n\ndef read_image(path):\n    path = path.decode()\n    image = cv2.imread(path, cv2.IMREAD_COLOR)\n    image = cv2.resize(image, (cf[\"image_size\"], cf[\"image_size\"]))\n    image = image / 255.0\n\n    \"\"\" Processing to patches \"\"\"\n    patch_shape = (cf[\"patch_size\"], cf[\"patch_size\"], cf[\"num_channels\"])\n    patches = patchify(image, patch_shape, cf[\"patch_size\"])\n    patches = np.reshape(patches, cf[\"flat_patches_shape\"])\n    patches = patches.astype(np.float32)\n\n    return patches\n\n\ndef read_mask(path):\n    path = path.decode()\n    mask = cv2.imread(path, cv2.IMREAD_GRAYSCALE)  # (256, 256)\n    mask = cv2.resize(mask, (cf[\"image_size\"], cf[\"image_size\"]))  # (256, 256)\n    mask = mask / 255.0  # (256, 256)\n    mask = mask.astype(np.float32)  # (256, 256)\n    mask = np.expand_dims(mask, axis=-1)  # (256, 256, 1)\n    return mask\n\n\ndef tf_parse(x, y):\n    def _parse(x, y):\n        x = read_image(x)\n        y = read_mask(y)\n        return x, y\n\n    x, y = tf.numpy_function(_parse, [x, y], [tf.float32, tf.float32])\n    x.set_shape(cf[\"flat_patches_shape\"])\n    y.set_shape([cf[\"image_size\"], cf[\"image_size\"], 1])\n    return x, y\n\n\ndef tf_dataset(X, Y, batch=2):\n    dataset = tf.data.Dataset.from_tensor_slices((X, Y))\n    dataset = dataset.map(tf_parse)\n    dataset = dataset.batch(batch)\n    dataset = dataset.prefetch(10)\n    return dataset\n","metadata":{"execution":{"iopub.status.busy":"2024-04-25T20:43:31.78916Z","iopub.execute_input":"2024-04-25T20:43:31.789857Z","iopub.status.idle":"2024-04-25T20:43:32.403175Z","shell.execute_reply.started":"2024-04-25T20:43:31.789821Z","shell.execute_reply":"2024-04-25T20:43:32.402397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Build the UNETR model","metadata":{}},{"cell_type":"markdown","source":"UNETR - Unet Transformer","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport keras.layers as L\nfrom keras.models import Model\n\n\ndef mlp(x, cf):\n    x = L.Dense(cf[\"mlp_dim\"], activation=\"gelu\")(x)\n    x = L.Dropout(cf[\"dropout_rate\"])(x)\n    x = L.Dense(cf[\"hidden_dim\"])(x)\n    x = L.Dropout(cf[\"dropout_rate\"])(x)\n    return x\n\n\ndef transformer_encoder(x, cf):\n    skip_1 = x\n    x = L.LayerNormalization()(x)\n    x = L.MultiHeadAttention(\n        num_heads=cf[\"num_heads\"], key_dim=cf[\"hidden_dim\"]\n    )(x, x)\n    x = L.Add()([x, skip_1])\n\n    skip_2 = x\n    x = L.LayerNormalization()(x)\n    x = mlp(x, cf)\n    x = L.Add()([x, skip_2])\n\n    return x\n\n\ndef conv_block(x, num_filters, kernel_size=3):\n    x = L.Conv2D(num_filters, kernel_size=kernel_size, padding=\"same\")(x)\n    x = L.BatchNormalization()(x)\n    x = L.ReLU()(x)\n    return x\n\n\ndef deconv_block(x, num_filters):\n    x = L.Conv2DTranspose(num_filters, kernel_size=2,\n                          padding=\"same\", strides=2)(x)\n    return x\n\n\ndef build_unetr(cf):\n    \"\"\" Inputs \"\"\"\n    input_shape = (cf[\"num_patches\"], cf[\"patch_size\"]\n                   * cf[\"patch_size\"]*cf[\"num_channels\"])\n    inputs = L.Input(input_shape)  # (None, 256, 768)\n\n    \"\"\" Patch + Position Embeddings \"\"\"\n    patch_embed = L.Dense(cf[\"hidden_dim\"])(inputs)  # (None, 256, 768)\n\n    positions = tf.range(start=0, limit=cf[\"num_patches\"], delta=1)  # (256,)\n    pos_embed = L.Embedding(input_dim=cf[\"num_patches\"], output_dim=cf[\"hidden_dim\"])(\n        positions)  # (256, 768)\n    x = patch_embed + pos_embed  # (None, 256, 768)\n\n    \"\"\" Transformer Encoder \"\"\"\n    skip_connection_index = [3, 6, 9, 12]\n    skip_connections = []\n\n    for i in range(1, cf[\"num_layers\"] + 1, 1):\n        x = transformer_encoder(x, cf)\n\n        if i in skip_connection_index:\n            skip_connections.append(x)\n\n    \"\"\" CNN Decoder \"\"\"\n    z3, z6, z9, z12 = skip_connections\n\n    # Reshaping\n    z0 = L.Reshape((cf[\"image_size\"], cf[\"image_size\"],\n                   cf[\"num_channels\"]))(inputs)\n    z3 = L.Reshape((cf[\"patch_size\"], cf[\"patch_size\"], cf[\"hidden_dim\"]))(z3)\n    z6 = L.Reshape((cf[\"patch_size\"], cf[\"patch_size\"], cf[\"hidden_dim\"]))(z6)\n    z9 = L.Reshape((cf[\"patch_size\"], cf[\"patch_size\"], cf[\"hidden_dim\"]))(z9)\n    z12 = L.Reshape(\n        (cf[\"patch_size\"], cf[\"patch_size\"], cf[\"hidden_dim\"]))(z12)\n\n    # Decoder 1\n    x = deconv_block(z12, 512)\n\n    s = deconv_block(z9, 512)\n    s = conv_block(s, 512)\n    x = L.Concatenate()([x, s])\n\n    x = conv_block(x, 512)\n    x = conv_block(x, 512)\n\n    # Decoder 2\n    x = deconv_block(x, 256)\n\n    s = deconv_block(z6, 256)\n    s = conv_block(s, 256)\n    s = deconv_block(s, 256)\n    s = conv_block(s, 256)\n\n    x = L.Concatenate()([x, s])\n    x = conv_block(x, 256)\n    x = conv_block(x, 256)\n\n    # Decoder 3\n    x = deconv_block(x, 128)\n\n    s = deconv_block(z3, 128)\n    s = conv_block(s, 128)\n    s = deconv_block(s, 128)\n    s = conv_block(s, 128)\n    s = deconv_block(s, 128)\n    s = conv_block(s, 128)\n\n    x = L.Concatenate()([x, s])\n    x = conv_block(x, 128)\n    x = conv_block(x, 128)\n\n    # Decoder 4\n    x = deconv_block(x, 64)\n\n    s = conv_block(z0, 64)\n    s = conv_block(s, 64)\n\n    x = L.Concatenate()([x, s])\n    x = conv_block(x, 64)\n    x = conv_block(x, 64)\n\n    \"\"\" Output \"\"\"\n    outputs = L.Conv2D(1, kernel_size=1, padding=\"same\",\n                       activation=\"sigmoid\")(x)\n\n    return Model(inputs, outputs, name=\"UNETR\")\n\n\nmodel = build_unetr(cf)\nmodel.summary()\n","metadata":{"execution":{"iopub.status.busy":"2024-04-25T20:43:38.767699Z","iopub.execute_input":"2024-04-25T20:43:38.768363Z","iopub.status.idle":"2024-04-25T20:43:42.017499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training the UNETR model","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport os\nfrom keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger, EarlyStopping\n\n\nsmooth = 1e-15\n\n\ndef dice_coef(y_true, y_pred):\n    y_true = tf.keras.layers.Flatten()(y_true)\n    y_pred = tf.keras.layers.Flatten()(y_pred)\n    intersection = tf.reduce_sum(y_true * y_pred)\n    return (2. * intersection + smooth) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + smooth)\n\n\ndef dice_loss(y_true, y_pred):\n    return 1.0 - dice_coef(y_true, y_pred)\n\n\n\"\"\" Seeding \"\"\"\nnp.random.seed(42)\ntf.random.set_seed(42)\n\n\"\"\" Directory for storing files \"\"\"\ncreate_dir(\"/kaggle/working/files\")\n\n\"\"\" Hyperparameters \"\"\"\nbatch_size = cf[\"batch_size\"]\noptimizer = cf[\"optimizer\"]\nnum_epochs = 1\nmodel_path = os.path.join(\"/kaggle/working/files\", \"model.h5\")\ncsv_path = os.path.join(\"/kaggle/working/files\", \"log.csv\")\n\n\"\"\" Dataset \"\"\"\ndataset_path = \"/kaggle/input/brain-tumor-segmentation\"\n(train_x, train_y), (valid_x, valid_y), (test_x, test_y) = load_dataset(dataset_path)\n\nprint(f\"Train: {len(train_x)} - {len(train_y)}\")\nprint(f\"Valid: {len(valid_x)} - {len(valid_y)}\")\nprint(f\"Test : {len(test_x)} - {len(test_y)}\")\n\ntrain_x, train_y = augment_data(train_x, train_y, num_aug_per_image=2, aug_save_path=\"/kaggle/working/aug_brain-tumor-segmentation\")\n\nprint(f\"Train after augmented: {len(train_x)} - {len(train_y)}\")\n\ntrain_dataset = tf_dataset(train_x, train_y, batch=batch_size)\nvalid_dataset = tf_dataset(valid_x, valid_y, batch=batch_size)\n\n\"\"\" Model \"\"\"\nmodel = build_unetr(cf)\nmodel.compile(loss=dice_loss, optimizer=optimizer, metrics=[dice_coef])\n\ncallbacks = [\n    ModelCheckpoint(model_path, verbose=1, save_best_only=True),\n    ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n                      patience=5, min_lr=1e-7, verbose=1),\n    CSVLogger(csv_path),\n    EarlyStopping(monitor='val_loss', patience=20,\n                  restore_best_weights=False),\n]\n\nmodel.fit(\n    train_dataset,\n    epochs=num_epochs,\n    validation_data=valid_dataset,\n    callbacks=callbacks\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-25T20:43:53.012356Z","iopub.execute_input":"2024-04-25T20:43:53.012763Z","iopub.status.idle":"2024-04-25T20:59:30.476522Z","shell.execute_reply.started":"2024-04-25T20:43:53.012732Z","shell.execute_reply":"2024-04-25T20:59:30.475571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Testing & Evaluation","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import f1_score, jaccard_score, precision_score, recall_score\nimport tensorflow as tf\nfrom tqdm import tqdm\nimport pandas as pd\nimport cv2\nimport numpy as np\nimport os\nfrom patchify import patchify","metadata":{"execution":{"iopub.status.busy":"2024-04-25T21:05:40.401915Z","iopub.execute_input":"2024-04-25T21:05:40.402718Z","iopub.status.idle":"2024-04-25T21:05:40.407506Z","shell.execute_reply.started":"2024-04-25T21:05:40.402685Z","shell.execute_reply":"2024-04-25T21:05:40.406631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def save_results(image, mask, y_pred, save_image_path):\n    mask = np.expand_dims(mask, axis=-1)\n    mask = np.concatenate([mask, mask, mask], axis=-1)\n\n    y_pred = np.expand_dims(y_pred, axis=-1)\n    y_pred = np.concatenate([y_pred, y_pred, y_pred], axis=-1)\n    y_pred = y_pred * 255\n\n    line = np.ones((cf[\"image_size\"], 10, 3)) * 255\n    \n    cat_images = np.concatenate([image, line, mask, line, y_pred], axis=1)\n    cv2.imwrite(save_image_path, cat_images)","metadata":{"execution":{"iopub.status.busy":"2024-04-25T21:05:52.609377Z","iopub.execute_input":"2024-04-25T21:05:52.610263Z","iopub.status.idle":"2024-04-25T21:05:52.616679Z","shell.execute_reply.started":"2024-04-25T21:05:52.610231Z","shell.execute_reply":"2024-04-25T21:05:52.615639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\" Seeding \"\"\"\nnp.random.seed(42)\ntf.random.set_seed(42)\n\n\"\"\" Directory for storing files \"\"\"\ncreate_dir(\"/kaggle/working/results\")\n\n\"\"\" Load the model \"\"\"\nmodel_path = os.path.join(\"/kaggle/working/files\", \"model.h5\")\nmodel = tf.keras.models.load_model(model_path, custom_objects={\"dice_loss\": dice_loss, \"dice_coef\": dice_coef})\n\n\"\"\" Dataset \"\"\"\ndataset_path = \"/kaggle/input/brain-tumor-segmentation\"\n(train_x, train_y), (valid_x, valid_y), (test_x,\n                                            test_y) = load_dataset(dataset_path)\n\n\"\"\" Prediction and Evaluation \"\"\"\nSCORE = []\nfor x, y in tqdm(zip(test_x, test_y), total=len(test_y)):\n    \"\"\" Extracting the name \"\"\"\n    name = x.replace(\"\\\\\", \"/\").split(\"/\")[-1]\n\n    \"\"\" Reading the image \"\"\"\n    image = cv2.imread(x, cv2.IMREAD_COLOR)  # [512, 512, 3]\n    image = cv2.resize(\n        image, (cf[\"image_size\"], cf[\"image_size\"]))  # [256, 256, 3]\n    x = image / 255.0  # [256, 256, 3]\n\n    patch_shape = (cf[\"patch_size\"], cf[\"patch_size\"], cf[\"num_channels\"]) # (16, 16, 3)\n    patches = patchify(x, patch_shape, cf[\"patch_size\"])\n    patches = np.reshape(patches, cf[\"flat_patches_shape\"]) # [256, 768]\n    patches = patches.astype(np.float32) # [256, 768]\n    patches = np.expand_dims(patches, axis=0) # [1, 256, 768]\n\n    \"\"\" Reading the mask \"\"\"\n    mask = cv2.imread(y, cv2.IMREAD_GRAYSCALE) # [512, 512]\n    mask = cv2.resize(mask, (cf[\"image_size\"], cf[\"image_size\"])) # [256, 256]\n\n    \"\"\" Prediction \"\"\"\n    y_pred = model.predict(patches, verbose=0)[0] # [256, 256, 1]\n    y_pred = np.squeeze(y_pred, axis=-1) # [256, 256]\n    y_pred = y_pred >= 0.5 # [256, 256]\n    y_pred = y_pred.astype(np.int32) # [256, 256]\n\n    \"\"\" Saving the prediction \"\"\"\n    save_image_path = os.path.join(\"/kaggle/working/results\", name)\n    save_results(image, mask, y_pred, save_image_path)\n\n    \"\"\" Flatten the array \"\"\"\n    mask = mask / 255.0\n    mask = (mask > 0.5).astype(np.int32).flatten()\n    y_pred = y_pred.flatten()\n\n    \"\"\" Calculating the metrics values \"\"\"\n    f1_value = f1_score(mask, y_pred, labels=[0, 1], average=\"binary\")\n    jac_value = jaccard_score(mask, y_pred, labels=[\n                                0, 1], average=\"binary\")\n    recall_value = recall_score(\n        mask, y_pred, labels=[0, 1], average=\"binary\", zero_division=0)\n    precision_value = precision_score(\n        mask, y_pred, labels=[0, 1], average=\"binary\", zero_division=0)\n    SCORE.append([name, f1_value, jac_value,\n                    recall_value, precision_value])\n    \n\"\"\" Metrics values \"\"\"\nscore = [s[1:]for s in SCORE]\nscore = np.mean(score, axis=0)\nprint(f\"F1: {score[0]:0.5f}\")\nprint(f\"Jaccard: {score[1]:0.5f}\")\nprint(f\"Recall: {score[2]:0.5f}\")\nprint(f\"Precision: {score[3]:0.5f}\")\n\ndf = pd.DataFrame(\n    SCORE, columns=[\"Image\", \"F1\", \"Jaccard\", \"Recall\", \"Precision\"])\ndf.to_csv(\"/kaggle/working/files/score.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-04-25T21:05:59.295803Z","iopub.execute_input":"2024-04-25T21:05:59.296489Z","iopub.status.idle":"2024-04-25T21:09:02.069692Z","shell.execute_reply.started":"2024-04-25T21:05:59.29646Z","shell.execute_reply":"2024-04-25T21:09:02.068704Z"},"trusted":true},"execution_count":null,"outputs":[]}]}